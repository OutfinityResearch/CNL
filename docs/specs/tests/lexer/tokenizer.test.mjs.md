# tests/lexer/tokenizer.test.mjs

## Purpose
Covers tokenization behavior and keyword longest-match rules.

## Expected Coverage
- IDENT vs keyword separation.
- Multi-word keyword grouping.
- Span correctness for tokens.
